# ==========================================
# STAGE 0: Compiler (For packages requiring GCC 9.3+)
# ==========================================
# Use Ubuntu to get GCC 10 for compiling scipy (which requires NumPy 2.x as build dep)
# We compile scipy here, then copy it to the Lambda base image
FROM ubuntu:22.04 AS compiler

# Install Python 3.11 and GCC 10
RUN apt-get update && \
    apt-get install -y python3.11 python3.11-dev python3-pip gcc-10 g++-10 make && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Set GCC 10 as default
RUN update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-10 100 && \
    update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-10 100

# Create directory for compiled packages
RUN mkdir -p /tmp/compiled-packages

# Install NumPy 1.x first (runtime requirement)
RUN python3.11 -m pip install --target /tmp/compiled-packages --no-cache-dir "numpy<2.0.0"

# Install scipy (use pre-built wheel if available, otherwise it will compile with GCC 10)
# Note: scipy's build dependencies require NumPy 2.x, but the resulting scipy works with NumPy 1.x
RUN python3.11 -m pip install --target /tmp/compiled-packages --no-cache-dir "scipy<2.0.0"

# ==========================================
# STAGE 1: Builder (Compiler & Downloader)
# ==========================================
# Note: AWS Lambda base images support both x86_64 and ARM64
# CDK will build for the specified architecture via --platform flag
FROM public.ecr.aws/lambda/python:3.11 AS builder

# 1. Install system tools
# Rust/GCC are needed for compiling dependencies like tiktoken or docling-core
# Try dnf first (Amazon Linux 2023), fall back to yum (Amazon Linux 2)
# Note: AL2 has GCC 7.3.1, which is insufficient for NumPy 2.x but we pin NumPy 1.x
RUN (dnf --version > /dev/null 2>&1 && \
     dnf update -y && \
     dnf install -y gcc gcc-c++ make mesa-libGL glib2 tar gzip curl ca-certificates && \
     dnf clean all) || \
    (yum update -y && \
     yum install -y gcc gcc-c++ make mesa-libGL glib2 tar gzip curl ca-certificates && \
     yum clean all)

# Install Rust (separate step for better error handling)
# Using explicit retry logic for network reliability in CI
RUN set -euxo pipefail && \
    echo "Installing Rust..." && \
    curl --version && \
    curl --proto "=https" --tlsv1.2 -sSf https://sh.rustup.rs | sh -s -- -y --default-toolchain stable && \
    echo "Rust installation completed successfully"

# 2. Set rust path
ENV PATH="/root/.cargo/bin:${PATH}"

# 3. Setup Directories
RUN mkdir -p /tmp/models/docling-artifacts \
    /tmp/models/tiktoken_cache \
    /tmp/packages

# 4. Copy ALL compiled packages from compiler stage (includes scipy and numpy)
# This ensures pip recognizes scipy as installed and won't try to rebuild it
COPY --from=compiler /tmp/compiled-packages/ /tmp/packages/

# 5. Install NumPy 1.x explicitly to overwrite NumPy 2.x from compiler stage
# scipy from compiler stage was built with NumPy 2.x, but works with NumPy 1.x at runtime
RUN pip install --target /tmp/packages --no-cache-dir --force-reinstall --no-deps "numpy<2.0.0" && \
    pip install --target /tmp/packages --no-cache-dir "numpy<2.0.0"

# 7. Install PyTorch CPU *Explicitly*
# Installing before requirements.txt ensures we get the lightweight CPU version and not the version that includes GPU support
RUN pip install \
    --target /tmp/packages \
    --no-cache-dir \
    --index-url https://download.pytorch.org/whl/cpu \
    torch

# 8. Install scipy using --only-binary to force using pre-built wheel (no source build)
# The compiler stage confirmed a wheel exists, so this should work
RUN pip install --target /tmp/packages --no-cache-dir --only-binary :all: "scipy<2.0.0"

# 9. Install Your Requirements  
# Use --no-build-isolation to prevent pip from trying to build scipy's dependencies
# scipy is already installed, so pip should use it
COPY ./backend/src/apis/app_api/documents/ingestion/requirements.txt .
RUN pip install \
    --target /tmp/packages \
    --no-cache-dir \
    --no-build-isolation \
    -r requirements.txt || \
    pip install \
        --target /tmp/packages \
        --no-cache-dir \
        -r requirements.txt

# 10. Download Tiktoken Vocabulary (Offline Support)
# We set PYTHONPATH so it can find the 'tiktoken' module in /tmp/packages
ENV TIKTOKEN_CACHE_DIR=/tmp/models/tiktoken_cache \
    PYTHONPATH=/tmp/packages

# We must ensure the directory exists before the script runs
RUN mkdir -p /tmp/models/tiktoken_cache && \
    python -c "import tiktoken; tiktoken.get_encoding('cl100k_base')"

# 11. Download Docling Models
# We use 'download_models' to fetch the standard pipeline (Layout, Tables, OCR).
# We force it to the specific artifacts folder.
ENV PYTHONPATH=/tmp/packages
RUN python -c "from docling.utils.model_downloader import download_models; \
    from pathlib import Path; \
    download_models( \
        output_dir=Path('/tmp/models/docling-artifacts'), \
        force=True \
    )"

# 12. Clean up OCR (Optimization)
# We delete the heavy EasyOCR model (~200MB) and the table structure model to keep the Lambda image slim
RUN rm -rf /tmp/models/docling-artifacts/easyocr \
    /tmp/models/docling-artifacts/table_structure_model

# ==========================================
# STAGE 2: Runtime (Production Image)
# ==========================================
FROM public.ecr.aws/lambda/python:3.11

# 1. Install only runtime system libs (GL/Glib for CV2)
# Try dnf first (Amazon Linux 2023), fall back to yum (Amazon Linux 2)
RUN (dnf --version > /dev/null 2>&1 && \
     dnf install -y mesa-libGL glib2 && \
     dnf clean all) || \
    (yum install -y mesa-libGL glib2 && \
     yum clean all)

# 2. Copy Python Packages
COPY --from=builder /tmp/packages ${LAMBDA_TASK_ROOT}

# 3. Copy Baked Models
# Docling Models (Read directly from /opt)
COPY --from=builder /tmp/models/docling-artifacts /opt/ml/models/docling-artifacts
# Tiktoken Cache (Must copy contents to a folder; handler will move this to /tmp)
COPY --from=builder /tmp/models/tiktoken_cache /opt/ml/models/tiktoken_cache/

# 4. Set Environment Variables
ENV DOCLING_ARTIFACTS_PATH=/opt/ml/models/docling-artifacts \
    # Point library to /tmp (handler copies files here at startup)
    TIKTOKEN_CACHE_DIR=/tmp/tiktoken_cache \
    PYTHONPATH=${LAMBDA_TASK_ROOT} \
    # PERFORMANCE FIXES
    OMP_NUM_THREADS=1 \
    MKL_NUM_THREADS=1 \
    PYTORCH_ENABLE_MPS_FALLBACK=1 \
    # CRITICAL: Disables NNPACK optimization to prevent "Out of Memory" crash
    USE_NNPACK=0 \
    # CRITICAL: Disables PyTorch hardware scan to prevent 60s startup hang
    TORCH_INDUCTOR_CACHE_DIR=/tmp/torch_inductor

# 5. Copy Your Handler Code
COPY backend/src/apis/app_api/documents/ingestion/ ${LAMBDA_TASK_ROOT}

CMD [ "handler.lambda_handler" ]