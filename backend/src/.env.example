# =============================================================================
# STRANDS AGENT CHATBOT - ENVIRONMENT CONFIGURATION
# =============================================================================
# 
# SETUP: Copy this file to .env and replace placeholder values
# 
# =============================================================================

# =============================================================================
# AWS & DEPLOYMENT CONFIGURATION
# =============================================================================

# AWS region for deployment
AWS_REGION=us-west-2

# AWS Profile (optional)
# If set, will use this AWS CLI profile for credentials
# If not set or "default", will use default AWS credential chain:
#   1. Environment variables (AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
#   2. AWS credentials file (~/.aws/credentials)
#   3. IAM role (if running on EC2/ECS)
# Examples: "default", "dev", "production", "my-profile"
AWS_PROFILE=default

# =============================================================================
# AGENTCORE MEMORY CONFIGURATION
# =============================================================================
# AgentCore Memory stores conversation history and user context (preferences, facts).
# This is SEPARATE from DYNAMODB_SESSIONS_METADATA_TABLE_NAME which stores cost/usage metadata.

# AgentCore Memory Storage Type
# Type: "file" (default, local development) or "dynamodb" (cloud)
# Purpose: Controls where conversation history is stored
# Local Development: Use "file" for local file-based storage (no AWS costs)
# Production: Use "dynamodb" to connect to AWS Bedrock AgentCore Memory service
# Default: file
AGENTCORE_MEMORY_TYPE=file

# AgentCore Memory ID (REQUIRED when AGENTCORE_MEMORY_TYPE=dynamodb)
# Purpose: AWS Bedrock AgentCore Memory ID for persistent conversation storage
# Local Development: Leave empty when using file storage
# Production: Set to your AgentCore Memory ID (AWS manages the underlying DynamoDB table)
# Features: Multi-session memory, user preferences, facts retrieval, 90-day retention
# Where to find: AWS Console > Amazon Bedrock > AgentCore > Memory
# Example: abc123def456
AGENTCORE_MEMORY_ID=

# AgentCore Gateway MCP Enabled (OPTIONAL)
# Purpose: Enable/disable AgentCore Gateway MCP tool integration
# If true (default), Gateway MCP tools are available to the agent
# If false, Gateway MCP is completely disabled (useful for local development without Gateway)
# Requires: Gateway deployed via GatewayStack and SSM parameter /{projectPrefix}/mcp/gateway-url
AGENTCORE_GATEWAY_MCP_ENABLED=true

# AgentCore Code Interpreter ID (OPTIONAL)
# Purpose: AWS Bedrock AgentCore Code Interpreter for executing Python code in a sandbox
# Features: Generate charts/diagrams with matplotlib, data analysis with pandas/numpy
# Supported: Python, JavaScript, TypeScript execution in isolated containers
# Execution time: Default 15 minutes, up to 8 hours configurable
# Where to find: AWS Console > Amazon Bedrock > AgentCore > Code Interpreter
# Example: abc123def456
AGENTCORE_CODE_INTERPRETER_ID=

# =============================================================================
# DEVELOPMENT SETTINGS
# =============================================================================

# Enable authentication (REQUIRED: set to true for production)
# If false, the app will be publicly accessible without authentication
ENABLE_AUTHENTICATION=false

# Enable quota enforcement (OPTIONAL)
# Purpose: Enforce user quota limits on chat requests
# If true, checks user quota before processing each request
# If false (default), quota system is disabled - all requests allowed
# Requires: DYNAMODB_QUOTA_TABLE and DYNAMODB_COST_SUMMARY_TABLE_NAME to be configured
# Behavior when enabled:
#   - Returns HTTP 429 when user exceeds their quota limit
#   - Injects quota_warning SSE event when approaching soft limit (80%, 90%)
#   - Logs block/warning events to DYNAMODB_QUOTA_EVENTS_TABLE
ENABLE_QUOTA_ENFORCEMENT=false

# =============================================================================
# BACKEND CONFIGURATION
# =============================================================================

# Directory for uploaded files (images, documents)
# Used by multimodal input processing and file upload endpoints
UPLOAD_DIR=uploads

# Directory for generated output files
# Used by code interpreter and other tools that generate files
OUTPUT_DIR=output

# Directory for AI-generated images
# Used by image generation tools and visualization outputs
GENERATED_IMAGES_DIR=generated_images

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================

# DynamoDB table for managed models (OPTIONAL)
# Purpose: Store model configurations (pricing, limits, availability) in production
# Local Development: Uses JSON file storage in backend/src/models/ if not set
# Production: Set to your DynamoDB table name for centralized model management
# Example: ManagedModels
DYNAMODB_MANAGED_MODELS_TABLE_NAME=

# DynamoDB table for message-level metadata (OPTIONAL - Cost Tracking)
# Purpose: Store per-message metadata including cost, tokens, latency, and pricing snapshots
# Local Development: Uses JSON files in sessions/session_{id}/message-metadata.json if not set
# Production: Set to your DynamoDB table name for scalable cost tracking
# Schema: PK=USER#<user_id>, SK=SESSION#<session_id>#MSG#<message_id>
# Features: Automatic TTL (365 days), GSI for time-range queries
# Example: SessionsMetadata
DYNAMODB_SESSIONS_METADATA_TABLE_NAME=

# DynamoDB table for user cost summaries (OPTIONAL - Cost Tracking)
# Purpose: Store pre-aggregated cost summaries for fast quota checks (<10ms)
# Local Development: Cost tracking disabled if not set (quota checks return null)
# Production: Required for production cost tracking and quota enforcement
# Schema: PK=USER#<user_id>, SK=PERIOD#<YYYY-MM>
# Features: Atomic increments, per-model breakdowns, cache savings calculation
# GSI: PeriodCostIndex (GSI2PK, GSI2SK) for admin dashboard top users query
# Example: UserCostSummary
DYNAMODB_COST_SUMMARY_TABLE_NAME=

# DynamoDB table for system cost rollups (OPTIONAL - Admin Dashboard)
# Purpose: Store system-wide cost aggregates for admin dashboard
# Local Development: Admin dashboard features disabled if not set
# Production: Required for admin cost dashboard functionality
# Schema:
#   - ROLLUP#DAILY, SK=<YYYY-MM-DD> for daily totals
#   - ROLLUP#MONTHLY, SK=<YYYY-MM> for monthly totals
#   - ROLLUP#MODEL, SK=<YYYY-MM>#<model_id> for per-model breakdown
# Features: Pre-aggregated metrics, real-time updates via async processing
# Example: SystemCostRollup
DYNAMODB_SYSTEM_ROLLUP_TABLE_NAME=

# DynamoDB table for OIDC authentication state (OPTIONAL)
# Purpose: Store OAuth/OIDC authentication state during login flow
# Local Development: Not needed if ENABLE_AUTHENTICATION=false
# Production: Required if using EntraID or other OIDC authentication
# Used to prevent CSRF attacks and validate authentication callbacks
# Example: OIDCState
DYNAMODB_OIDC_STATE_TABLE_NAME=

# DynamoDB table for quota management (OPTIONAL - Quota System)
# Purpose: Store quota tiers and user/role assignments for usage limits
# Local Development: Use "UserQuotas" or "UserQuotas-dev" if testing quota system
# Production: Set to your DynamoDB table name (e.g., UserQuotas-prod)
# Schema: Supports tiers, direct user assignments, JWT role assignments, and default tiers
# Features: Priority-based resolution, 5-minute caching, zero table scans
# CDK Deployment: See cdk/lib/stacks/quota-stack.ts for infrastructure
# Example: UserQuotas-dev
DYNAMODB_QUOTA_TABLE=

# DynamoDB table for quota events (OPTIONAL - Quota System)
# Purpose: Track quota enforcement events (blocks, warnings) for analytics
# Local Development: Use "QuotaEvents" or "QuotaEvents-dev" if testing quota system
# Production: Set to your DynamoDB table name (e.g., QuotaEvents-prod)
# Schema: Stores block events with user, tier, usage, and timestamp information
# Features: Time-ordered queries, tier-based analytics, automatic GSI indexing
# CDK Deployment: See cdk/lib/stacks/quota-stack.ts for infrastructure
# Example: QuotaEvents-dev
DYNAMODB_QUOTA_EVENTS_TABLE=

# DynamoDB table for user profiles (OPTIONAL - User Admin)
# Purpose: Store user profiles synced from JWT for admin user lookup
# Local Development: Leave empty to disable user sync (admin user lookup disabled)
# Production: Set to your DynamoDB table name for admin user management
# Schema: PK=USER#<user_id>, SK=PROFILE
# GSIs: UserIdIndex (deep links), EmailIndex (search), EmailDomainIndex, StatusLoginIndex
# Features: JWT sync on login, admin deep links from cost dashboard
# CDK Deployment: See infrastructure/lib/app-api-stack.ts
# Example: Users-dev
DYNAMODB_USERS_TABLE_NAME=

# DynamoDB table for AppRoles (OPTIONAL - RBAC System)
# Purpose: Store application roles and JWT-to-permission mappings
# Local Development: Leave empty to disable RBAC (falls back to JWT role checks)
# Production: Set to your DynamoDB table name for role-based access control
# Schema: PK=ROLE#{role_id}, SK=DEFINITION (role definitions)
#         PK=ROLE#{role_id}, SK=JWT_MAPPING#{jwt_role} (JWT mappings)
# GSIs: JwtRoleMappingIndex (JWT->AppRole lookup), ToolRoleMappingIndex, ModelRoleMappingIndex
# Features: Role inheritance, permission caching, bidirectional sync
# CDK Deployment: See infrastructure/lib/app-api-stack.ts
# Example: AppRoles-dev
DYNAMODB_APP_ROLES_TABLE_NAME=

# DynamoDB table for file metadata (REQUIRED for file uploads)
# Purpose: Store file metadata, ownership, and quota tracking
# Local Development: Use a local DynamoDB table or DynamoDB Local
# Production: Set to your DynamoDB table name from CDK deployment
# Schema: PK=USER#<user_id>, SK=FILE#<upload_id> for file metadata
#         PK=USER#<user_id>, SK=QUOTA for user quota tracking
# GSI: SessionFilesIndex for querying files by session
# CDK Deployment: Created by AppApiStack
# Example: bsu-agentcore-user-files-dev
DYNAMODB_USER_FILES_TABLE_NAME=

# Admin JWT Roles (OPTIONAL - RBAC System)
# Purpose: Specify which JWT roles grant system administrator access
# Format: JSON array of role names (e.g., ["Admin", "SuperAdmin"])
# Default: ["DotNetDevelopers"]
# Note: System admins have full access to RBAC management and cannot be locked out
# Example: ["DotNetDevelopers", "AgentCoreAdmin"]
ADMIN_JWT_ROLES=["DotNetDevelopers"]

# =============================================================================
# RBAC CACHE CONFIGURATION (OPTIONAL)
# =============================================================================
# Configure cache TTL values for the RBAC system
# These control how long role and permission data is cached before refresh

# User permissions cache TTL (minutes)
# How long user effective permissions are cached
# Default: 5
APP_ROLE_USER_CACHE_TTL_MINUTES=5

# Role definition cache TTL (minutes)
# How long role definitions are cached
# Default: 10
APP_ROLE_ROLE_CACHE_TTL_MINUTES=10

# JWT mapping cache TTL (minutes)
# How long JWT-to-AppRole mappings are cached
# Default: 10
APP_ROLE_MAPPING_CACHE_TTL_MINUTES=10

# =============================================================================
# FRONTEND CONFIGURATION
# =============================================================================

# Backend API URL
# Used by the frontend to make API requests to the backend
# Local Development: http://localhost:8000 (default FastAPI port)
# Production: Set to your deployed API URL (e.g., https://api.yourdomain.com)
API_URL=http://localhost:8000

# Frontend application URL
# Used for CORS configuration and OAuth redirects
# Local Development: http://localhost:4200 (default Angular port)
# Production: Set to your deployed frontend URL (e.g., https://app.yourdomain.com)
# Note: The port 42000 in the example appears to be a typo - should typically be 4200
FRONTEND_URL=http://localhost:4200

# =============================================================================
# CORS & SECURITY CONFIGURATION
# =============================================================================

# CORS allowed origins - comma-separated list of domains allowed to make requests
# Purpose: Configure Cross-Origin Resource Sharing for browser security
# Local Development: Include all local development URLs (frontend, backend, different ports)
# Production: Set to your production frontend URL(s) only for security
# Example Production: https://app.yourdomain.com,https://www.yourdomain.com
# WARNING: Never use "*" in production - it allows any website to access your API
CORS_ORIGINS=http://localhost:4200,http://127.0.0.1:4200,http://localhost:8000,http://127.0.0.1:8080

# =============================================================================
# MULTI-PROVIDER LLM CONFIGURATION
# =============================================================================
# The agent supports three LLM providers: AWS Bedrock (default), OpenAI, and Google Gemini
# Only configure the API keys for providers you plan to use
# Models must be added via the Admin UI (/admin/models) before they can be used

# OpenAI API Key (OPTIONAL)
# Purpose: Enable OpenAI models (GPT-4, GPT-4o, etc.) as LLM provider options
# Get your API key from: https://platform.openai.com/api-keys
# Supported models: gpt-4o, gpt-4o-mini, gpt-4-turbo, o1-preview, o1-mini
# Cost: OpenAI charges per token usage - see https://openai.com/pricing
# Note: OpenAI models do NOT support prompt caching (cache pricing fields ignored)
OPENAI_API_KEY=

# Google Gemini API Key (OPTIONAL)
# Purpose: Enable Google Gemini models as LLM provider options
# Get your API key from: https://aistudio.google.com/apikey
# Supported models: gemini-2.5-flash, gemini-2.5-pro, gemini-1.5-flash, gemini-1.5-pro
# Cost: Google charges per token usage - see https://ai.google.dev/pricing
# Note: Gemini models do NOT support prompt caching (cache pricing fields ignored)
GOOGLE_GEMINI_API_KEY=

# AWS Bedrock (DEFAULT PROVIDER)
# Purpose: AWS Bedrock is the default and primary LLM provider
# Authentication: Uses AWS credentials configured above (AWS_PROFILE or access keys)
# Supported models: Claude Sonnet, Claude Opus, Claude Haiku (all versions)
# Cost: Bedrock charges per token usage - see https://aws.amazon.com/bedrock/pricing/
# Features: ONLY Bedrock supports prompt caching (90% discount on cache reads)
# Example model IDs: us.anthropic.claude-sonnet-4-5-20250929-v1:0
# No API key needed - uses IAM authentication



# =============================================================================
# MCP SERVER CONFIGURATION
# =============================================================================
# MCP (Model Context Protocol) servers provide additional capabilities to the agent
# These are third-party services that require API keys

# Tavily Web Search API Key (OPTIONAL)
# Purpose: Enable real-time web search capabilities for the agent
# Get your API key from: https://tavily.com/
# Features: Search the web, get current information, research topics
# Free tier: 1,000 searches/month
# Required for: Web search tool, research capabilities
TAVILY_API_KEY=your_tavily_api_key_here

# Cludo Search Site Key (OPTIONAL)
# Purpose: Enable Boise State University search capabilities via Cludo search engine
# Features: Search institutional information, policies, programs, directories, and official Boise State resources
# Required for: search_boise_state tool
# Get your site key from: Contact Boise State IT or Cludo administrator
TOOL_CLUDO_SITE_KEY=

# Nova Act Browser API Key (OPTIONAL)
# Purpose: Enable browser automation and web interaction capabilities
# Get your API key from: https://nova-act.com/dashboard
# Features: Automated web browsing, taking screenshots, filling forms
# Use cases: Web scraping, testing, automated workflows
# Note: Requires Claude models with vision capabilities for screenshot analysis
NOVA_ACT_API_KEY=your_nova_act_api_key_here

# =============================================================================
# ENTRA ID (AZURE AD) AUTHENTICATION CONFIGURATION
# =============================================================================
# Configure Microsoft Entra ID (formerly Azure Active Directory) for SSO authentication
# Required only if ENABLE_AUTHENTICATION=true and using Microsoft/Office 365 accounts
# Setup guide: https://learn.microsoft.com/entra/identity-platform/quickstart-register-app

# Entra ID Tenant ID (REQUIRED for EntraID auth)
# Purpose: Identifies your Azure AD / Microsoft 365 organization
# Where to find: Azure Portal > Entra ID > Overview > Tenant ID
# Format: GUID (e.g., 12345678-1234-1234-1234-123456789abc)
ENTRA_TENANT_ID=

# Entra ID Application (Client) ID (REQUIRED for EntraID auth)
# Purpose: Identifies your registered application in Azure AD
# Where to find: Azure Portal > App Registrations > Your App > Application ID
# Format: GUID (e.g., 87654321-4321-4321-4321-210987654321)
ENTRA_CLIENT_ID=

# Entra ID Client Secret (REQUIRED for EntraID auth)
# Purpose: Authentication secret for your application (like a password)
# Where to find: Azure Portal > App Registrations > Your App > Certificates & secrets
# Security: Keep this secret! Never commit to version control
# Note: Secrets expire - set a reminder to rotate before expiration
ENTRA_CLIENT_SECRET=

# Entra ID Redirect URI (REQUIRED for EntraID auth)
# Purpose: Where Azure AD redirects users after authentication
# Must match EXACTLY what's configured in Azure Portal > App Registrations > Authentication
# Local Development: http://localhost:4200/auth/callback
# Production: https://your-domain.com/auth/callback
# Note: Must use HTTPS in production (except localhost)
ENTRA_REDIRECT_URI=http://localhost:4200/auth/callback

# =============================================================================
# FILE UPLOAD CONFIGURATION
# =============================================================================
# Configure file upload capabilities for attaching documents to conversations
# Files are stored in S3 with metadata in DynamoDB

# S3 bucket for user file uploads (REQUIRED for file uploads)
# Purpose: Store uploaded files (PDFs, documents, etc.) for conversation context
# Local Development: Use a local S3 bucket or LocalStack
# Production: Set to your S3 bucket name from CDK deployment
# CDK Deployment: Created by AppApiStack with intelligent tiering lifecycle rules
# Example: bsu-agentcore-user-files-dev
S3_USER_FILES_BUCKET_NAME=

# Maximum file size in bytes (OPTIONAL)
# Purpose: Limit individual file upload size
# Default: 4194304 (4MB) - Bedrock document processing limit
# Supported: Up to 4.5MB for Bedrock, but 4MB recommended for safety
FILE_UPLOAD_MAX_SIZE_BYTES=4194304

# Maximum files per message (OPTIONAL)
# Purpose: Limit number of files attached to a single message
# Default: 5
# Bedrock limit: 5 documents per request
FILE_UPLOAD_MAX_FILES_PER_MESSAGE=5

# User storage quota in bytes (OPTIONAL)
# Purpose: Limit total storage per user across all sessions
# Default: 1073741824 (1GB)
# Note: Quota is enforced before file upload, not after
FILE_UPLOAD_USER_QUOTA_BYTES=1073741824